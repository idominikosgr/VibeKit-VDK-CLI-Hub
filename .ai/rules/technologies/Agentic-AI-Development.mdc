---
description: Best practices for developing agentic AI applications with different AI models and frameworks.
globs: ["**/*.py", "**/*.js", "**/*.ts", "**/langchain/**", "**/llama_index/**", "**/agent*.py", "**/agent*.js"]
alwaysApply: false
version: "1.0.0"
lastUpdated: "2025-05-14"
compatibleWith: ["Python3", "TypeScript-Modern", "Memory-MCP", "Sequential-Thinking"]
---

# Agentic AI Development Best Practices

## Foundation Model Selection
- Choose the appropriate AI model based on your specific requirements:
  - **GPT-4/GPT-4o**: Best for complex reasoning, code generation, and multi-step planning
  - **Claude 3 Sonnet**: Good balance of performance and cost for many applications
- Consider performance characteristics beyond just capabilities:
  - Latency requirements
  - Token limitations
  - Cost structure
  - API availability and reliability
  - Fine-tuning options
  - Specialization (e.g., code, vision, reasoning)
- Implement model fallbacks for reliability and cost management.
- Consider multi-model approaches for different tasks within the same application.
- Evaluate models with benchmark tasks specific to your use case.

## Prompt Engineering
- Start with clear instructions that specify the task, context, format, and constraints.
- Use explicit formatting in prompts including headers, bullet points, and numbered lists.
- Structure complex prompts with clear sections:
  ```
  # TASK
  You will analyze the given code for security vulnerabilities.

  # INPUT FORMAT
  You will receive a code snippet in Python.

  # OUTPUT FORMAT
  Provide a numbered list of potential vulnerabilities with:
  1. Description of the vulnerability
  2. Line number(s) affected
  3. Severity rating (Low/Medium/High)
  4. Suggested fix

  # EXAMPLE
  [Example input and output to demonstrate expectations]

  # CODE TO ANALYZE
  [Code would be inserted here]
  ```
- For different model families, adjust your prompting style:
  - **GPT-4/o**: Direct, clear instructions with explicit formatting works well
  - **Claude 3.7 Sonnet**: Responds well to role-based prompting and detailed instructions
- Implement few-shot examples for complex or ambiguous tasks.
- Use JSON mode or structured output format for programmatic consumption.
- Consider implementing Chain-of-Thought prompting for complex reasoning tasks.
- Test prompts with different phrasing to find optimal performance.
- Document effective prompts for reuse and consistency.
- Implement prompt versioning to track changes and improvements.

## Agent Architecture Design
- Design your agent with clear reasoning steps:
  1. **Goal Understanding**: Clearly define what the agent needs to accomplish
  2. **Planning**: Break down goals into actionable steps
  3. **Tool Selection**: Choose appropriate tools for each step
  4. **Execution**: Carry out actions with tools
  5. **Reflection**: Evaluate results and adjust approach
  6. **Learning**: Incorporate feedback for improvement
- Implement the ReAct (Reasoning + Acting) paradigm for complex tasks.
- Use a modular architecture to separate concerns:
  - Core reasoning engine
  - Tool integration layer
  - Memory management
  - User interaction handling
  - Feedback processing
- Design your agent to be robust to model limitations:
  - Handle hallucinations gracefully
  - Verify critical information
  - Implement safeguards against prompt injection
- Consider the agent's operational context:
  - Autonomous vs. assisted operation
  - Synchronous vs. asynchronous processing
  - Single-turn vs. multi-turn interaction
- Implement graceful degradation when facing limitations.
- Design for extensibility to add new capabilities over time.

## Memory Systems
- Implement appropriate memory structures based on agent needs:
  - **Short-term memory**: Current conversation or task state
  - **Working memory**: Active information during complex tasks
  - **Long-term memory**: Persistent knowledge across sessions
  - **Episodic memory**: Records of past experiences and interactions
  - **Semantic memory**: Conceptual understanding and domain knowledge
- Use vector databases for semantic search across large memory stores.
- Consider hierarchical memory structures for complex agents:
  ```python
  class AgentMemory:
      def __init__(self):
          self.short_term = deque(maxlen=10)  # Recent interactions
          self.working_memory = {}  # Current task state
          self.long_term = VectorStore()  # Persistent memories
          
      def remember(self, memory, memory_type="short_term"):
          # Implementation
          
      def recall(self, query, memory_type="all"):
          # Implementation
  ```
- Implement memory consolidation to transfer important information from short-term to long-term memory.
- Design appropriate forgetting mechanisms to prevent memory overload.
- Implement regular memory summarization for efficient context utilization.
- Consider privacy and security implications of persistent memory.
- Test memory systems with diverse scenarios and edge cases.
- Implement memory introspection capabilities for debugging and transparency.

## Tool Integration
- Design a consistent interface for tool integration:
  ```python
  class Tool:
      def __init__(self, name, description, function, parameters):
          self.name = name
          self.description = description  # Clear description for the agent
          self.function = function  # The actual implementation
          self.parameters = parameters  # Parameter schema
          
      def execute(self, **kwargs):
          # Parameter validation
          # Function execution
          # Result formatting
  ```
- Provide clear tool descriptions that explain:
  - What the tool does
  - When to use it
  - Required parameters and their formats
  - Example usage
  - Potential errors or limitations
- Implement proper error handling for tool execution.
- Consider the appropriate level of tool abstraction:
  - Low-level primitive tools
  - Mid-level capability tools
  - High-level composite tools
- Design tools to be self-contained and idempotent where possible.
- Implement tool usage logging for debugging and improvement.
- Consider security implications of each tool and implement appropriate safeguards.
- Test tools independently and in combination to ensure reliable operation.
- Document tool interfaces and examples for future developers.

## Sequential Thinking Implementation
- Implement structured reasoning frameworks for complex problems:
  ```python
  def solve_problem(agent, problem):
      # 1. Problem understanding
      problem_analysis = agent.analyze(problem)
      
      # 2. Break down into sub-problems
      sub_problems = agent.decompose(problem_analysis)
      
      # 3. Plan solution approach
      solution_plan = agent.create_plan(sub_problems)
      
      # 4. Execute plan with reflection
      partial_results = []
      for step in solution_plan:
          result = agent.execute_step(step)
          reflection = agent.reflect_on_result(result, step)
          if reflection.requires_revision:
              # Revise plan and continue
          partial_results.append(result)
      
      # 5. Synthesize final solution
      return agent.synthesize(partial_results)
  ```
- Use explicit thinking steps with clear transitions:
  1. **Observation**: Gather relevant information
  2. **Reflection**: Consider implications and connections
  3. **Hypothesis**: Form potential explanations or approaches
  4. **Planning**: Design steps to test hypotheses
  5. **Action**: Execute planned steps
  6. **Evaluation**: Assess results and refine understanding
- Implement backtracking capabilities for when reasoning paths prove unproductive.
- Design for explicit uncertainty handling in the reasoning process.
- Use tree-of-thought approaches for exploring multiple reasoning paths.
- Implement verification steps for critical reasoning components.
- Consider computational budget constraints in complex reasoning chains.
- Design appropriate stopping conditions to prevent infinite loops.
- Document the reasoning approach for transparency and debugging.

## LangChain/LlamaIndex Integration
- Use LangChain for standardized agent construction:
  ```python
  from langchain.agents import create_structured_chat_agent
  from langchain.memory import ConversationBufferMemory
  
  memory = ConversationBufferMemory()
  agent = create_structured_chat_agent(
      llm=gpt4,
      tools=tools,
      memory=memory,
      verbose=True
  )
  ```
- Leverage LlamaIndex for knowledge retrieval and indexing:
  ```python
  from llama_index import VectorStoreIndex, SimpleDirectoryReader
  
  documents = SimpleDirectoryReader('data').load_data()
  index = VectorStoreIndex.from_documents(documents)
  query_engine = index.as_query_engine()
  ```
- Use appropriate chains for specific use cases:
  - `ReAct` chains for tool-using agents
  - `MapReduce` chains for processing large datasets
  - `Sequential` chains for fixed workflows
  - `Router` chains for dynamic workflow selection
- Implement custom callbacks for observability and tracking.
- Consider using the LCEL (LangChain Expression Language) for composable patterns.
- Design appropriate prompts for each component in your chain.
- Implement proper error handling and retry logic.
- Use streaming responses for better user experience with long-running operations.
- Consider batch processing for efficiency with multiple similar tasks.
- Test chains with diverse inputs to ensure robustness.

## Evaluating AI-Generated Code
- Implement a systematic code review process for AI-generated code:
  1. **Correctness**: Does the code perform the intended function?
  2. **Security**: Are there potential vulnerabilities or unsafe practices?
  3. **Performance**: Are there obvious inefficiencies or bottlenecks?
  4. **Maintainability**: Is the code well-structured and documented?
  5. **Edge Cases**: Does the code handle unexpected inputs or conditions?
- Use automated tools to supplement manual review:
  - Linters and static analyzers
  - Security scanning tools
  - Unit test generation
  - Complexity metrics
- Apply consistent evaluation criteria across different generation attempts.
- Consider implementing automated test generation alongside code generation.
- Document known limitations or areas requiring human oversight.
- Implement feedback loops to improve future code generation.
- Maintain a library of successful patterns and anti-patterns.

## Human-AI Collaboration
- Design interaction patterns that leverage the strengths of both AI and humans:
  - AI: Pattern recognition, consistency, memory, breadth of knowledge
  - Humans: Judgment, creativity, context awareness, values alignment
- Implement appropriate feedback mechanisms:
  - Explicit feedback for correcting errors
  - Implicit feedback through interaction patterns
  - Structured evaluation for systematic improvement
- Design for appropriate autonomy levels based on task criticality and AI capability.
- Create clear escalation paths for situations requiring human intervention.
- Implement appropriate transparency in AI reasoning and decision-making.
- Consider the cognitive load on human collaborators and design accordingly.
- Test collaboration patterns with diverse users and scenarios.
- Document collaboration guidelines for consistent interaction.

## Ethics and Safety
- Implement guardrails for preventing harmful outputs:
  - Content filtering for inappropriate material
  - Fact-checking critical information
  - Bias detection and mitigation
  - Privacy protection for sensitive data
- Design with transparency as a core principle:
  - Clear disclosure of AI involvement
  - Explainable reasoning processes
  - Accessible documentation of capabilities and limitations
- Consider the ethical implications of agent capabilities:
  - Potential for misuse
  - Impact on user autonomy
  - Accessibility and inclusivity
  - Environmental impact of computation
- Implement appropriate consent mechanisms for data usage.
- Design for graceful failure when facing ethically ambiguous requests.
- Conduct regular ethical reviews of agent behavior and impact.
- Document ethical guidelines and boundaries for development.

## Deployment and Scaling
- Consider appropriate deployment architectures based on requirements:
  - Serverless for variable workloads
  - Container-based for predictable scaling
  - Edge deployment for latency-sensitive applications
  - Hybrid approaches for balancing needs
- Implement appropriate caching strategies:
  - Prompt caching for common queries
  - Result caching for expensive operations
  - Embedding caching for retrieval efficiency
- Design for observability with comprehensive logging and monitoring:
  - Prompt tracking
  - Token usage
  - Latency metrics
  - Error rates
  - User satisfaction indicators
- Implement appropriate cost management strategies:
  - Model selection based on task complexity
  - Token optimization
  - Batching where appropriate
  - Caching frequently requested results
- Consider regulatory compliance requirements in deployment design.
- Implement appropriate scaling patterns for handling load variations.
- Design for resilience with proper fallback mechanisms.
- Document deployment architecture and operational procedures.
